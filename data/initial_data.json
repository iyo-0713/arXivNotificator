[
    {
        "title": "Attention is all you need", 
        "link": "https://doi.org/10.48550/arXiv.1706.03762"
    },
    {
        "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback", 
        "link": "https://arxiv.org/abs/2204.05862"
    },
    {
        "title": "Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?", 
        "link": "https://doi.org/10.48550/arXiv.2405.05904"
    },
    {
        "title": "Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches", 
        "link": "https://arxiv.org/abs/2404.14779"
    },
    {
        "title": "RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture", 
        "link": "https://arxiv.org/abs/2401.08406"
    },
    {
        "title": "Fine-tuning Language Models for Factuality", 
        "link": "https://doi.org/10.48550/arXiv.2311.08401"
    },
    {
        "title": "A Persona-Based Neural Conversation Model", 
        "link": "https://doi.org/10.48550/arXiv.1603.06155"
    },
    {
        "title": "A Survey on Evaluation of Large Language Models", 
        "link": "https://arxiv.org/abs/2307.03109"
    },
    {
        "title": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions", 
        "link": "https://arxiv.org/abs/2311.05232"
    },
    {
        "title": "A Survey of Large Language Models", 
        "link": "https://doi.org/10.48550/arXiv.2303.18223"
    }
]
